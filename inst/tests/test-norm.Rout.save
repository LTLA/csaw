
R Under development (unstable) (2017-10-27 r73632) -- "Unsuffered Consequences"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # This tests the correctness of the normOffsets functions.
> 
> suppressPackageStartupMessages(library(csaw))
> suppressPackageStartupMessages(library(edgeR))
> 
> ###################################################
> 
> # First we test for scaling normalization.
> 
> set.seed(1000)
> data <- SummarizedExperiment(matrix(rpois(10000, lambda=10), ncol=10))
> data$totals <- rpois(10, lambda=10000)
> 
> nf <- normOffsets(data, se.out=FALSE)
> ref <- calcNormFactors(DGEList(assay(data), lib.size=data$totals), doWeighting=FALSE)$samples$norm.factors
> stopifnot(identical(nf, ref))
> ref
 [1] 0.9863660 1.0056529 0.9930955 0.9906736 1.0062443 0.9949424 1.0178486
 [8] 0.9731044 1.0120422 1.0210561
> 
> data2 <- normOffsets(data, se.out=TRUE)
> stopifnot(identical(data2$norm.factors, ref))
> stopifnot(identical(data2$totals, data$totals))
> 
> # Checking that overwriting se.out works.
> 
> data3 <- data
> assay(data3) <- assay(data3)*runif(nrow(data3))
> data3b <- normOffsets(data, se.out=data3)
> stopifnot(identical(assay(data3b), assay(data3)))
> stopifnot(identical(data3b$norm.factors, ref))
> 
> data3$totals <- rpois(10, lambda=10000)
> try(normOffsets(data, se.out=data3)) # should chuck an error.
Error in .local(object, ...) : 
  library sizes of 'se.out' and 'object' are not identical
> 
> ###################################################
> 
> # Additional fixed-value checks; testing what happens when we add some undersampling.
> 
> n <- 1000L
> mu1 <- rep(10, n)
> mu2 <- mu1
> mu2[1:100] <- 100
> undersamp <- sum(mu1)/sum(mu2)
> mu2 <- mu2*undersamp
> counts <- cbind(rnbinom(n, mu=mu1, size=20), rnbinom(n, mu=mu2, size=20))
> 
> actual.lib.size <- c(sum(mu1), sum(mu2))
> normOffsets(counts, lib.sizes=actual.lib.size)
[1] 1.3314266 0.7510741
> normOffsets(counts, logratioTrim=0.4, lib.sizes=actual.lib.size)
[1] 1.3349650 0.7490833
> normOffsets(counts, sumTrim=0.3, lib.size=actual.lib.size)
[1] 1.3503767 0.7405341
> sqrt(c(1/undersamp, undersamp)) # True values, looks pretty good.
[1] 1.3784049 0.7254763
> 
> # Testing what happens with weighting, after adding some high-abundance DB regions. 
> 
> n <- 100000
> blah <- matrix(rnbinom(2*n, mu=10, size=20), ncol=2)
> tospike <- 10000
> blah[1:tospike,1] <- rnbinom(tospike, mu=1000, size=20)
> blah[1:tospike,2] <- rnbinom(tospike, mu=2000, size=20)
> full.lib.size <- colSums(blah)
> 
> true.value <- 1/full.lib.size
> true.value <- true.value/exp(mean(log(true.value)))
> true.value
[1] 1.3839608 0.7225638
> 
> normOffsets(blah, lib.sizes=full.lib.size)
[1] 1.3346758 0.7492456
> normOffsets(blah, weighted=TRUE, lib.sizes=full.lib.size) # less accurate.
[1] 1.2592865 0.7941005
> 
> ###################################################
> 
> # Now we throw in some tests for loess normalization.
> 
> set.seed(1000)
> means <- 2^runif(1000)
> data <- SummarizedExperiment(matrix(rpois(10000, lambda=means), ncol=10))
> data$totals <- rpois(10, lambda=10000)
> 
> offs <- normOffsets(data, type="loess", se.out=FALSE)
> data <- normOffsets(data, type="loess", se.out=TRUE)
> stopifnot(identical(dim(offs), dim(assay(data, "offset"))))
> stopifnot(all(abs(offs-assay(data, "offset")) < 1e-8))
> head(offs)
            [,1]          [,2]         [,3]        [,4]        [,5]
[1,] -0.02227835 -0.0643205757  0.041991333 0.012669927  0.02364960
[2,] -0.09160860  0.0233966608  0.008694502 0.027579174  0.07150862
[3,] -0.05386784 -0.0005826292  0.093404411 0.106716062 -0.06628233
[4,] -0.08514091  0.0027327122 -0.027340615 0.008469965  0.09732159
[5,] -0.09724156  0.0048092804  0.019558639 0.058935125  0.09533275
[6,] -0.04963759 -0.0128770919  0.047613104 0.083567830 -0.01818793
             [,6]        [,7]        [,8]        [,9]        [,10]
[1,] -0.001598928  0.01107123 -0.03558446 -0.05927600  0.093676210
[2,]  0.020928937 -0.09892680 -0.02778508  0.06287768  0.003334910
[3,] -0.079229263 -0.04811863 -0.09932787  0.04918788  0.098100202
[4,]  0.114013469 -0.05139528 -0.04280452 -0.01208423 -0.003772181
[5,] -0.117300947 -0.04664940  0.02428223 -0.02201348  0.080287358
[6,] -0.056515463 -0.02414981 -0.10482637  0.03690445  0.098108877
> 
> try(normOffsets(data, type="loess", se.out=data))
Error in .local(object, ...) : 
  alternative output object not supported for loess normalization
> 
> # Reference calculation, after subtracting the reference 'ab' from the observed values.
> 
> lib.sizes <- data$totals
> mat <- assay(data)
> 
> cont.cor <- 0.5
> cont.cor.scaled <- cont.cor * lib.sizes/mean(lib.sizes)
> ab <- aveLogCPM(mat, lib.size=lib.sizes, prior.count=cont.cor)/log2(exp(1))
> 
> ref <- matrix(0, nrow(mat), ncol(mat), byrow=TRUE)
> for (x in seq_len(ncol(mat))) {
+     fit <- loessFit(log(mat[,x]+cont.cor.scaled[x]) - ab, ab) # explicit subtraction this time.
+     ref[,x] <- fit$fitted 
+ }
> ref <- ref-rowMeans(ref)
> 
> stopifnot(isTRUE(all.equal(ref, offs)))
> 
> ###################################################
> # End.
> 
> proc.time()
   user  system elapsed 
  8.056   0.164   8.247 
